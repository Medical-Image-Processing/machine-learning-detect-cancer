{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN for lesion classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Brief CNN theory\n",
    "\n",
    "A Convolutional Neural Network (CNN, or ConvNet) is a type of **feed-forward** artificial neural network in which the connectivity pattern between its neurons is inspired by the organization of the animal visual cortex."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/convnets_cover.png\" width=\"70%\" />\n",
    "\n",
    "> source: https://flickrcode.files.wordpress.com/2014/10/conv-net2.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Structure of a CNN\n",
    "\n",
    "> A more detailed overview of what CNNs do would be that you take the image, pass it through a series of convolutional, nonlinear, pooling (downsampling), and fully connected layers, and get an output. As we said earlier, the output can be a single class or a probability of classes that best describes the image. \n",
    "\n",
    "source: [1]\n",
    "\n",
    "#### Convolutional Layer\n",
    "\n",
    "The first layer in a CNN is always a **Convolutional Layer**.\n",
    "\n",
    "<img src=\"images/same_padding_no_strides.gif\" width=\"50%\">\n",
    "\n",
    "#### Typical CNN Structure\n",
    "\n",
    "A traditional CNN architecture consists of other layers interspaced between convolution layers\n",
    "\n",
    "<img src=\"images/Table.png\">\n",
    "\n",
    "#### Pooling layer\n",
    "\n",
    "After some ReLu layers, **pooling layer** is typically applied.\n",
    "\n",
    "<img src=\"images/MaxPool.png\" width=\"80%\"/>\n",
    "\n",
    "Pooling reduces the amount of parameters (helping with computional efficiency) and controls overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. We build one using keras and tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup code for this notebook\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from functions import data, Timer\n",
    "timer = Timer()\n",
    "\n",
    "# This makes matplotlib figures appear inline in the notebook\n",
    "# rather than in a new window.\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# Make the notebook reload external python modules;\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The ultra sound scan data\n",
    "- 163 scans total, clinically confirmed as having either bening or malignant (cancerous) lesions \n",
    "- 100 scans for training, 63 for testing\n",
    "- Training data was passed through 7 transformations to give us 800 training images total\n",
    "- 650 images used for training, 150 for validation\n",
    "- Testing images not transformed\n",
    "- Both training and testing images were resized to 224X224 this time round (optimal for inception in this case)\n",
    "- Raw pngs then converted to numpy arrays and saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Import keras libraries\n",
    "from keras.models import Sequential\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from functions import data, Timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape (224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "img_rows, img_cols = 224, 224 # 224, 224 works resized down from 360, 528\n",
    "color_channels = 3\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (color_channels, img_rows, img_cols)\n",
    "else:\n",
    "    input_shape = (img_rows, img_cols, color_channels)\n",
    "    \n",
    "print('Input shape', input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data loader and generator helper methods\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 650 images belonging to 2 classes.\n",
      "Found 150 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# data readers\n",
    "base = \"J:\\\\final year project\\\\code and models\\\\data\\\\augmented\\\\\"\n",
    "train_directory = base+'training'\n",
    "validation_directory = base+'validation'\n",
    "\n",
    "batch_size = 8\n",
    "\n",
    "# normalization\n",
    "train_generator = ImageDataGenerator(rescale=1./255)\n",
    "validation_generator = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# this is a generator that will read scans found in\n",
    "# the train directory, and indefinitely generate\n",
    "# batches of image data\n",
    "train_generator = train_generator.flow_from_directory(\n",
    "        train_directory,\n",
    "        target_size=(img_rows, img_cols),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')\n",
    "\n",
    "# A  similar generator, for validation data\n",
    "validation_generator = validation_generator.flow_from_directory(\n",
    "        validation_directory,\n",
    "        target_size=(img_rows, img_cols),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "def visualize(model):\n",
    "    model.summary()\n",
    "    SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getModelMemoryUsage(batch_size, model):\n",
    "    shapes_mem_count = 0\n",
    "    for l in model.layers:\n",
    "        single_layer_mem = 1\n",
    "        for s in l.output_shape:\n",
    "            if s is None:\n",
    "                continue\n",
    "            single_layer_mem *= s\n",
    "        shapes_mem_count += single_layer_mem\n",
    "\n",
    "    trainable_count = np.sum([K.count_params(p) for p in set(model.trainable_weights)])\n",
    "    non_trainable_count = np.sum([K.count_params(p) for p in set(model.non_trainable_weights)])\n",
    "\n",
    "    total_memory = 4.0*batch_size*(shapes_mem_count + trainable_count + non_trainable_count)\n",
    "    gbytes = np.round(total_memory / (1024.0 ** 3), 3)\n",
    "    return str(gbytes) + \" GB\" , str(gbytes*2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Retraining InceptionV3 CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We define the custom inception based model\n",
    "def buildBaseModel():\n",
    "    input_tensor = Input(shape=input_shape)\n",
    "    base_model = InceptionV3(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
    "    \n",
    "    # we add a global spatial average pooling layer\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    \n",
    "    # we add a fully-connected layer\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    \n",
    "    #we add a logistic layer for our 2 classes\n",
    "    predictions = Dense(1, activation='softmax')(x)\n",
    "    \n",
    "    # this is our model, a hybrid inceptionv3\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    \n",
    "    # first we train our custom top layer\n",
    "    # we freeze all convolutional inceptionv3 layers\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "        \n",
    "    model.compile(optimizer='adagrad',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = buildBaseModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helpers for checkpointing and early stopping\n",
    "from keras.callbacks import ModelCheckpoint , EarlyStopping\n",
    "\n",
    "def trainModel(model, epochs=10, text=\"Re training inception model\",\n",
    "              file_name='best_cnn_inc_model.h5'):\n",
    "    best_model_file = file_name\n",
    "    early_stop = EarlyStopping(monitor='val_loss', patience=3, verbose=True) \n",
    "    best_model = ModelCheckpoint(best_model_file, verbose=True, save_best_only=True)\n",
    "\n",
    "    timer.start()\n",
    "    network_history = model.fit_generator(\n",
    "            train_generator, \n",
    "            steps_per_epoch=200,\n",
    "            epochs=epochs,\n",
    "            validation_data = validation_generator,\n",
    "            validation_steps=50,\n",
    "            verbose=True,\n",
    "            callbacks=[best_model])\n",
    "    timer.stop(text)\n",
    "    return network_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.514 GB\n"
     ]
    }
   ],
   "source": [
    "# visualize(model)\n",
    "model.summary()\n",
    "gpu, ram = getModelMemoryUsage(batch_size, model)\n",
    "print(\"GPU Memory:\" + gpu + \"RAM:\" + ram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "200/200 [==============================] - 70s 349ms/step - loss: 10.7213 - acc: 0.3275 - val_loss: 10.7452 - val_acc: 0.3260\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 10.74517, saving model to best_cnn_inc_model.h5\n",
      "Epoch 2/50\n",
      "200/200 [==============================] - 69s 344ms/step - loss: 10.6415 - acc: 0.3325 - val_loss: 10.6495 - val_acc: 0.3320\n",
      "\n",
      "Epoch 00002: val_loss improved from 10.74517 to 10.64951, saving model to best_cnn_inc_model.h5\n",
      "Epoch 3/50\n",
      "200/200 [==============================] - 68s 341ms/step - loss: 10.7531 - acc: 0.3255 - val_loss: 10.6495 - val_acc: 0.3320\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/50\n",
      "200/200 [==============================] - 68s 342ms/step - loss: 10.5937 - acc: 0.3355 - val_loss: 10.6814 - val_acc: 0.3300\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/50\n",
      "200/200 [==============================] - 69s 343ms/step - loss: 10.8010 - acc: 0.3225 - val_loss: 10.5539 - val_acc: 0.3380\n",
      "\n",
      "Epoch 00005: val_loss improved from 10.64951 to 10.55386, saving model to best_cnn_inc_model.h5\n",
      "Epoch 6/50\n",
      "200/200 [==============================] - 69s 344ms/step - loss: 10.6973 - acc: 0.3290 - val_loss: 10.6495 - val_acc: 0.3320\n",
      "\n",
      "Epoch 00006: val_loss did not improve\n",
      "Epoch 7/50\n",
      "200/200 [==============================] - 69s 345ms/step - loss: 10.7053 - acc: 0.3285 - val_loss: 10.5539 - val_acc: 0.3380\n",
      "\n",
      "Epoch 00007: val_loss did not improve\n",
      "Epoch 8/50\n",
      "200/200 [==============================] - 69s 345ms/step - loss: 10.6973 - acc: 0.3290 - val_loss: 10.5857 - val_acc: 0.3360\n",
      "\n",
      "Epoch 00008: val_loss did not improve\n",
      "Epoch 9/50\n",
      "200/200 [==============================] - 68s 340ms/step - loss: 10.5778 - acc: 0.3365 - val_loss: 10.7771 - val_acc: 0.3240\n",
      "\n",
      "Epoch 00009: val_loss did not improve\n",
      "Epoch 10/50\n",
      "200/200 [==============================] - 68s 342ms/step - loss: 10.7292 - acc: 0.3270 - val_loss: 10.5857 - val_acc: 0.3360\n",
      "\n",
      "Epoch 00010: val_loss did not improve\n",
      "Epoch 11/50\n",
      "200/200 [==============================] - 68s 340ms/step - loss: 10.7292 - acc: 0.3270 - val_loss: 10.7452 - val_acc: 0.3260\n",
      "\n",
      "Epoch 00011: val_loss did not improve\n",
      "Epoch 12/50\n",
      "200/200 [==============================] - 68s 340ms/step - loss: 10.6575 - acc: 0.3315 - val_loss: 10.6176 - val_acc: 0.3340\n",
      "\n",
      "Epoch 00012: val_loss did not improve\n",
      "Epoch 13/50\n",
      "200/200 [==============================] - 68s 339ms/step - loss: 10.7133 - acc: 0.3280 - val_loss: 10.6495 - val_acc: 0.3320\n",
      "\n",
      "Epoch 00013: val_loss did not improve\n",
      "Epoch 14/50\n",
      "200/200 [==============================] - 68s 338ms/step - loss: 10.6973 - acc: 0.3290 - val_loss: 10.6495 - val_acc: 0.3320\n",
      "\n",
      "Epoch 00014: val_loss did not improve\n",
      "Epoch 15/50\n",
      "200/200 [==============================] - 68s 338ms/step - loss: 10.6814 - acc: 0.3300 - val_loss: 10.7133 - val_acc: 0.3280\n",
      "\n",
      "Epoch 00015: val_loss did not improve\n",
      "Epoch 16/50\n",
      "200/200 [==============================] - 68s 339ms/step - loss: 10.7133 - acc: 0.3280 - val_loss: 10.5857 - val_acc: 0.3360\n",
      "\n",
      "Epoch 00016: val_loss did not improve\n",
      "Epoch 17/50\n",
      "200/200 [==============================] - 68s 339ms/step - loss: 10.6336 - acc: 0.3330 - val_loss: 10.7133 - val_acc: 0.3280\n",
      "\n",
      "Epoch 00017: val_loss did not improve\n",
      "Epoch 18/50\n",
      "200/200 [==============================] - 68s 338ms/step - loss: 10.7850 - acc: 0.3235 - val_loss: 10.5857 - val_acc: 0.3360\n",
      "\n",
      "Epoch 00018: val_loss did not improve\n",
      "Epoch 19/50\n",
      "200/200 [==============================] - 68s 338ms/step - loss: 10.6655 - acc: 0.3310 - val_loss: 10.7133 - val_acc: 0.3280\n",
      "\n",
      "Epoch 00019: val_loss did not improve\n",
      "Epoch 20/50\n",
      "200/200 [==============================] - 69s 343ms/step - loss: 10.6814 - acc: 0.3300 - val_loss: 10.4901 - val_acc: 0.3420\n",
      "\n",
      "Epoch 00020: val_loss improved from 10.55386 to 10.49009, saving model to best_cnn_inc_model.h5\n",
      "Epoch 21/50\n",
      "200/200 [==============================] - 68s 341ms/step - loss: 10.7053 - acc: 0.3285 - val_loss: 10.6495 - val_acc: 0.3320\n",
      "\n",
      "Epoch 00021: val_loss did not improve\n",
      "Epoch 22/50\n",
      "200/200 [==============================] - 69s 344ms/step - loss: 10.6973 - acc: 0.3290 - val_loss: 10.5539 - val_acc: 0.3380\n",
      "\n",
      "Epoch 00022: val_loss did not improve\n",
      "Epoch 23/50\n",
      "200/200 [==============================] - 69s 345ms/step - loss: 10.5937 - acc: 0.3355 - val_loss: 10.7133 - val_acc: 0.3280\n",
      "\n",
      "Epoch 00023: val_loss did not improve\n",
      "Epoch 24/50\n",
      "200/200 [==============================] - 68s 342ms/step - loss: 10.7850 - acc: 0.3235 - val_loss: 10.6814 - val_acc: 0.3300\n",
      "\n",
      "Epoch 00024: val_loss did not improve\n",
      "Epoch 25/50\n",
      "200/200 [==============================] - 68s 342ms/step - loss: 10.6973 - acc: 0.3290 - val_loss: 10.5220 - val_acc: 0.3400\n",
      "\n",
      "Epoch 00025: val_loss did not improve\n",
      "Epoch 26/50\n",
      "200/200 [==============================] - 69s 347ms/step - loss: 10.6814 - acc: 0.3300 - val_loss: 10.6176 - val_acc: 0.3340\n",
      "\n",
      "Epoch 00026: val_loss did not improve\n",
      "Epoch 27/50\n",
      "200/200 [==============================] - 68s 342ms/step - loss: 10.7053 - acc: 0.3285 - val_loss: 10.4901 - val_acc: 0.3420\n",
      "\n",
      "Epoch 00027: val_loss did not improve\n",
      "Epoch 28/50\n",
      "200/200 [==============================] - 68s 340ms/step - loss: 10.7213 - acc: 0.3275 - val_loss: 10.7133 - val_acc: 0.3280\n",
      "\n",
      "Epoch 00028: val_loss did not improve\n",
      "Epoch 29/50\n",
      "200/200 [==============================] - 69s 346ms/step - loss: 10.6894 - acc: 0.3295 - val_loss: 10.6814 - val_acc: 0.3300\n",
      "\n",
      "Epoch 00029: val_loss did not improve\n",
      "Epoch 30/50\n",
      "200/200 [==============================] - 69s 347ms/step - loss: 10.6814 - acc: 0.3300 - val_loss: 10.5539 - val_acc: 0.3380\n",
      "\n",
      "Epoch 00030: val_loss did not improve\n",
      "Epoch 31/50\n",
      "200/200 [==============================] - 69s 344ms/step - loss: 10.7531 - acc: 0.3255 - val_loss: 10.4901 - val_acc: 0.3420\n",
      "\n",
      "Epoch 00031: val_loss improved from 10.49009 to 10.49009, saving model to best_cnn_inc_model.h5\n",
      "Epoch 32/50\n",
      "200/200 [==============================] - 69s 344ms/step - loss: 10.5778 - acc: 0.3365 - val_loss: 10.5539 - val_acc: 0.3380\n",
      "\n",
      "Epoch 00032: val_loss did not improve\n",
      "Epoch 33/50\n",
      "200/200 [==============================] - 69s 344ms/step - loss: 10.8010 - acc: 0.3225 - val_loss: 10.6176 - val_acc: 0.3340\n",
      "\n",
      "Epoch 00033: val_loss did not improve\n",
      "Epoch 34/50\n",
      "200/200 [==============================] - 69s 344ms/step - loss: 10.7452 - acc: 0.3260 - val_loss: 10.5539 - val_acc: 0.3380\n",
      "\n",
      "Epoch 00034: val_loss did not improve\n",
      "Epoch 35/50\n",
      "200/200 [==============================] - 69s 345ms/step - loss: 10.5299 - acc: 0.3395 - val_loss: 10.6495 - val_acc: 0.3320\n",
      "\n",
      "Epoch 00035: val_loss did not improve\n",
      "Epoch 36/50\n",
      "200/200 [==============================] - 69s 345ms/step - loss: 10.6814 - acc: 0.3300 - val_loss: 10.8727 - val_acc: 0.3180\n",
      "\n",
      "Epoch 00036: val_loss did not improve\n",
      "Epoch 37/50\n",
      "200/200 [==============================] - 71s 357ms/step - loss: 10.7372 - acc: 0.3265 - val_loss: 10.5220 - val_acc: 0.3400\n",
      "\n",
      "Epoch 00037: val_loss did not improve\n",
      "Epoch 38/50\n",
      "200/200 [==============================] - 70s 351ms/step - loss: 10.6814 - acc: 0.3300 - val_loss: 10.4901 - val_acc: 0.3420\n",
      "\n",
      "Epoch 00038: val_loss did not improve\n",
      "Epoch 39/50\n",
      "200/200 [==============================] - 69s 344ms/step - loss: 10.7133 - acc: 0.3280 - val_loss: 10.4582 - val_acc: 0.3440\n",
      "\n",
      "Epoch 00039: val_loss improved from 10.49009 to 10.45820, saving model to best_cnn_inc_model.h5\n",
      "Epoch 40/50\n",
      "200/200 [==============================] - 69s 343ms/step - loss: 10.7053 - acc: 0.3285 - val_loss: 10.6495 - val_acc: 0.3320\n",
      "\n",
      "Epoch 00040: val_loss did not improve\n",
      "Epoch 41/50\n",
      "200/200 [==============================] - 69s 346ms/step - loss: 10.6973 - acc: 0.3290 - val_loss: 10.6814 - val_acc: 0.3300\n",
      "\n",
      "Epoch 00041: val_loss did not improve\n",
      "Epoch 42/50\n",
      "200/200 [==============================] - 68s 342ms/step - loss: 10.6575 - acc: 0.3315 - val_loss: 10.5857 - val_acc: 0.3360\n",
      "\n",
      "Epoch 00042: val_loss did not improve\n",
      "Epoch 43/50\n",
      "200/200 [==============================] - 68s 339ms/step - loss: 10.6655 - acc: 0.3310 - val_loss: 10.6495 - val_acc: 0.3320\n",
      "\n",
      "Epoch 00043: val_loss did not improve\n",
      "Epoch 44/50\n",
      "200/200 [==============================] - 68s 339ms/step - loss: 10.7771 - acc: 0.3240 - val_loss: 10.7771 - val_acc: 0.3240\n",
      "\n",
      "Epoch 00044: val_loss did not improve\n",
      "Epoch 45/50\n",
      "200/200 [==============================] - 68s 340ms/step - loss: 10.6814 - acc: 0.3300 - val_loss: 10.6176 - val_acc: 0.3340\n",
      "\n",
      "Epoch 00045: val_loss did not improve\n",
      "Epoch 46/50\n",
      "200/200 [==============================] - 68s 339ms/step - loss: 10.7930 - acc: 0.3230 - val_loss: 10.7133 - val_acc: 0.3280\n",
      "\n",
      "Epoch 00046: val_loss did not improve\n",
      "Epoch 47/50\n",
      "200/200 [==============================] - 68s 338ms/step - loss: 10.5459 - acc: 0.3385 - val_loss: 10.6814 - val_acc: 0.3300\n",
      "\n",
      "Epoch 00047: val_loss did not improve\n",
      "Epoch 48/50\n",
      "200/200 [==============================] - 68s 338ms/step - loss: 10.8089 - acc: 0.3220 - val_loss: 10.8727 - val_acc: 0.3180\n",
      "\n",
      "Epoch 00048: val_loss did not improve\n",
      "Epoch 49/50\n",
      "200/200 [==============================] - 68s 338ms/step - loss: 10.6176 - acc: 0.3340 - val_loss: 10.7133 - val_acc: 0.3280\n",
      "\n",
      "Epoch 00049: val_loss did not improve\n",
      "Epoch 50/50\n",
      "200/200 [==============================] - 68s 339ms/step - loss: 10.6973 - acc: 0.3290 - val_loss: 10.4901 - val_acc: 0.3420\n",
      "\n",
      "Epoch 00050: val_loss did not improve\n",
      "Timing:: took 57 minutes Re training on our data with frozen inception layers\n"
     ]
    }
   ],
   "source": [
    "history = trainModel(model, \n",
    "                     50, \n",
    "                     \"Re training on our data with frozen inception layers\", \"lower.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "print(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "625/625 [==============================] - 650s 1s/step - loss: 10.4830 - acc: 0.3424 - val_loss: 11.3754 - val_acc: 0.2865\n",
      "Epoch 2/3\n",
      "625/625 [==============================] - 646s 1s/step - loss: 10.4884 - acc: 0.3421 - val_loss: 11.3941 - val_acc: 0.2853\n",
      "Epoch 3/3\n",
      "625/625 [==============================] - 645s 1s/step - loss: 10.4905 - acc: 0.3420 - val_loss: 11.3816 - val_acc: 0.2861\n",
      "Timing:: took 32 minutes Re training the full inception model\n"
     ]
    }
   ],
   "source": [
    "# building the rest of the model\n",
    "\n",
    "# here we choose to retrain the top 2 inception blocks\n",
    "for layer in model.layers[:249]:\n",
    "    layer.trainable = False\n",
    "for layer in model.layers[249:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "# we now recompile the model for our layer modifications to take effect\n",
    "# we start with SGD with a low learning rate\n",
    "from keras.optimizers import SGD\n",
    "model.compile(optimizer=SGD(lr=0.0001, momentum=0.9),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history_2 = trainModel(model, \n",
    "                       50,\n",
    "                       \"Re training the full inception model\",\n",
    "                       '5.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(network_history):\n",
    "    plt.figure()\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.plot(network_history.history['loss'])\n",
    "    plt.plot(network_history.history['val_loss'])\n",
    "    plt.legend(['Training', 'Validation'])\n",
    "\n",
    "    plt.figure()\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.plot(network_history.history['acc'])\n",
    "    plt.plot(network_history.history['val_acc'])\n",
    "    plt.legend(['Training', 'Validation'], loc='lower right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Evaluating the CNNs performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get test data\n",
    "x_test, y_test = data.getTestData()\n",
    "print('Test data shape: ', x_test.shape)\n",
    "print('Test labels shape: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = x_test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and evaluate best model\n",
    "from keras.models import load_model\n",
    "best_model = load_model('5.h5')\n",
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.predict_classes(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printMetrics(tn, fp, fn, tp):\n",
    "    sensitivity = tp/(tp+fn)\n",
    "    \n",
    "    print(\"True Positive Rate (TPR) or Hit Rate or Recall or Sensitivity: \"\n",
    "          , sensitivity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate all\n",
    "from sklearn.metrics import confusion_matrix\n",
    "expected = y_test\n",
    "prediction = best_model.predict_classes(x_test)\n",
    "x, y, fn, tp = confusion_matrix(y_test, prediction).ravel()\n",
    "printMetrics(fn, tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printMetrics(tn, fp, fn, tp):\n",
    "    sensitivity = tp/(tp+fn)\n",
    "    specificity = tn/(tn+fp)\n",
    "    accuracy = (tp+tn)/(tp+tn+fp+fn)\n",
    "    error_rate = 1 - accuracy\n",
    "    precision = tp/(tp+fp)\n",
    "    f_measure = 2/((1/precision)+(1/sensitivity))\n",
    "    \n",
    "    print(\"True Positive Rate (TPR) or Hit Rate or Recall or Sensitivity: \"\n",
    "          , sensitivity)\n",
    "    print(\"False Positive Rate(FPR) or False Alarm Rate: \"\n",
    "          , 1 - specificity)\n",
    "    print(\"Accuracy: \", accuracy)\n",
    "    print(\"Error rate: \", error_rate)\n",
    "    print(\"Precision: \", precision)\n",
    "    print(\"F measure: \", f_measure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate all\n",
    "from sklearn.metrics import confusion_matrix\n",
    "expected = y_test\n",
    "prediction = best_model.predict_classes(x_test)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, prediction).ravel()\n",
    "print(tn, fp, fn, tp)\n",
    "printMetrics(tn, fp, fn, tp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References for images and some content:\n",
    "\n",
    "\\[1\\] [https://adeshpande3.github.io/adeshpande3.github.io/]() \n",
    "<br> \\[2\\] [\"Neural Networks and Deep Learning\"](http://neuralnetworksanddeeplearning.com/) by Michael Nielsen.\n",
    "<br> \\[3\\] Deep learning with TensorFlow and Keras by Valerio Maggio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
